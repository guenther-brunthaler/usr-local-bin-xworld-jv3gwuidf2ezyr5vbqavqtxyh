#! /bin/sh
show_version() {
	wrL <<-.
	$APP version 9.325

	(c) 2009 by Guenther Brunthaler.
	Distribution is allowed under the terms of the GPLv3.
.
}


show_help() {
	{
	wr <<-.
	$APP - create a check point for a directory tree which can later be
	compared in order to find any changes to its file data and most of its
	metadata.

.
	wrL <<-.
	
	Usage: $APP create <checkpoint_file> <directory_tree>
	       $APP compare <checkpoint_file> [ <directory_tree> ]
.
	wr <<-.

	In addition, global options can be specified before the command verbs
	(such as "create"):

	--: Stop parsing for command line options. Any arguments following
	this option will be interpreted as normal arguments, even if they
	start with "-" or "--".
	
	--save-metadata <savefile>, -m <savefile>: Only a hash over the
	metadata is included within the checkpoint file. If this option is
	specified, an additional file <savefile> is written containing the
	metadata that was used to create the hashes. The file consists of
	lines of (hash, metadata)-pairs, sorted by hash. This allows to find a
	matching hash efficiently using the "look" utility.

	--save-hardlink-paths <savefile>, -H <savefile>: Even when
	--save-metadata has been specified, the saved metadata will not
	include the hardlink paths but rather a hash of it. This option will
	create an additional save file containing the hardlinked paths, each
	one prefixed by the hash of the hardlink group as used in a file
	created by --metadata file. The file will be sorted by hash. This
	allows to find a matching hash efficiently using the "look" utility.

	--help, -h, --usage: Display this help.

	--version, -V: Show version information.

	--verbose, -v: Be more verbose.
	
	"Switch clustering" for short-options (single-dash options) is
	supported. For instance, when specifying two separate options "-v" and
	"-q", the combined option argument "-vq" means exactly the same thing.
	
	
	Command verb "create":
	
	This will gather information about all the file system objects (files,
	directories, symlinks, device files, fifos, sockets and whatever else
	there might be) and create a hash over the metadata of each object.
	
	For file objects only, a hash over the file contents is also included
	as part of the metadata to be hashed.
	
	This collected data is written to the checkpoint file, prefixed by a
	header including a hash over the remainder of the file. This means it
	is sufficient to compare the hash of two checkpoint files in order to
	determine whether they refer to directory trees with identical
	contents. See the file format description below for more details.
	
	
	Command verb "compare":
	
	Compare the contents of the specified checkpoint file with the
	directory tree location recorded in the checkpoint file, or with the
	directory tree specified as the second argument (ignoring the recorded
	location).
	
	Not yet implemented. Maybe never will.
	
	For the time being, use "diff -u" to compare two checkpoint files for
	differences in order to achieve approximately the same effect.
	
	In order to do this, first create another checkpoint file for the
	directory to be compared, then compare the original checkpoint file
	against the new one.

	
	Contents of a checkpoint file:
	
	The first line contains a version marker in order to be able to detect the
	file format. This will always be the same text for all checkpoints created
	by the same version of $APP.
	
	The second line contains the tree location used to create the checkpoint as
	an absolute and canonicalized path. Any symlinks will have been resolved.
	
	The third line contains the hash over the remaining lines. If this line is the same
	in two different checkpoint files, it is therefore not necessary to also compare the
	contents of the remaining lines: They must be identical.
	
	The fourth and following lines contain the hashes of all file system objects in
	the directory tree, ordered lexicographically using binary byte semantics. Any
	locale-specific collation sequences are ignored.
	
	However, the path names of the file system objects are encoded using
	the current character encoding (LC_CTYPE), so the same character set
	encoding for filenames (such as UTF-8) must be used for creating all
	checkpoint files which are to be compared against each other.
	
	All hashes will be created using the MD5 message digest algorithm.
	
	The following "stat" metadata for all filesystem objects is included
	within the hash:
.
	wrL <<-.

	* Access rights
	* Number of hard links
	* UID/GID of owner
	* Object type
	* Number of allocated blocks and block size according to stat()
	* Byte size as reported by "stat"
	* Time of last modification
	* In case of normal files, a hash over the files contents
	* In case of symlinks, a hash over the symlink destination pathname
	* In case of special devices, the device type
	* For hardlinked files, as hash over all paths (see below)
.
	wrL <<-.
	
	Note that neither the inode nor the device number are among the
	metadata to be checkpointed.
	
	This allows copies of directoriy trees to be compared against each
	other.
	
	This restriction is rather unfortunate for hardlinked files, because
	it does not retain the information which of the files in the tree
	refer to the same contents.
	
	In order to alleviate this, for each hardlinked file a list of
	(relative) path names is generated which all refer to the same file,
	as long as the file is also part of the checkpointed directory tree.
	
	This list of relative path names is then sorted and a hash over the
	resulting text is generated, which is included into the metadata of
	the hardlinked file system objects.
	
	The fact that the number of allocated blocks is also recorded, means
	that the amount of "sparseness" of files is also part of the
	checkpoint metadata.
.
	show_version
	} | less -e
}



die() {
	printf "ERROR: %s\n" "$*" >& 2
	false; exit
}


run() {
	"$@" && return
	die "Could not execute >>>$*<<< return code ${?}!"
}


system() {
	REPLY=`run "$@"` || exit
}


wr() {
	if
		test $# -gt 0
	then
		print '%s\n' "$*" | wr
	else
		fmt -w `tput cols`
	fi
}


wrL() {
	local LINE
	while
		IFS= read -r LINE
	do
		printf "%s\n" "$LINE" | wr
	done
}


inform() {
	test -z "$VERBOSE" && return
	printf "Info: %s\n" "$*" | wr >& 2
}


warn() {
	printf "Warning: %s\n" "$*" | wr >& 2
}


canonpath() {
	system readlink -f "$1"
}


extract_hash() {
	# It seems md5sum may prefix the hash with escape characters.
	# This happens for instance if the filename contains backslashes.
	run sed -e 's/^[^0-9a-f]*\([0-9a-f]\{32\}\).*$/\1/'
}


hashit() {
	run md5sum -b | extract_hash
}


hashargs() {
	run printf '%s\n' "$*" | hashit
}


hashlink() {
	run readlink "$1" | hashit
}


hashfile() {
	run md5sum -b "$1" | extract_hash
}


cleanup250() {
	test -z "$REDIR250" && return
	REDIR250=
	exec 250>& -
}


redir250() {
	exec 250> "$1"
	REDIR250=Y
}


cleanup() {
	cleanup250
	rm -r "$TFB"
}


# Prints a new "$LAST_ID $HASH" if $LAST_ID is non-empty.
# $HASH is the hash of $TMP1.
# $TMP1 is truncated after this.
flush_linkid() {
	local REPLY HASH
	if test -n "$LAST_ID"
	then
		system hashfile "$TMP1"; HASH=$REPLY
		echo "$LAST_ID $HASH"
		if test -n "$SAVE_HARDLINKS"
		then
			run sed -e "s/^/$HASH /" "$TMP1" >& 250
		fi
	fi
	true > "$TMP1"
}


VERBOSE=
SAVE_METADATA=
SAVE_HARDLINKS=
APP=${0##*/}
COPTS=
while
	:
do
	if
		test -z "$COPTS"
	then
		case "$1" in
			-?*) COPTS="$1"; shift;;
			*) break;;
		esac
	fi
	if
		test "${COPTS#--}" = "$COPTS"
	then
		TAIL="${COPTS#-?}"; # Switch clustering.
		COPT="${COPTS%$TAIL}"; COPTS="${TAIL:+-}$TAIL"
	else
		COPT="$COPTS"; COPTS=
	fi
	# Any arguments are at $1 and onwards; must be shifted off.
	case "$COPT" in
		--) break;; # Must be first!
		--save-metadata | -m) SAVE_METADATA=$1; shift;;
		--save-hardlink-paths | -H) SAVE_HARDLINKS=$1; shift;;
		--help | -h | --usage) show_help; exit;;
		--version | -V) show_version; exit;;
		--verbose | -v) VERBOSE=1;;
		*) die "Unknown option '$COPT'!";; # Must be last!
	esac
done
test x"$1" = x"create" || die "Unsupported command verb. See --help for help."
shift
test $# -eq 2 || die "Incorrect number of arguments."
CHECKPOINT_FILE=$1; shift
SOURCE_TREE=$1; shift
test -d "$SOURCE_TREE" || die "\"$SOURCE_TREE\" is not a directory!"
canonpath "$SOURCE_TREE"; SOURCE_TREE=$REPLY
run test -d "$SOURCE_TREE"
if test -e "$CHECKPOINT_FILE"
then
	test -f "$CHECKPOINT_FILE" \
		|| die "Refusing to overwrite non-file \"$CHECKPOINT_FILE\"!"
fi

LC_COLLATE="C"
LC_NUMERIC=$LC_COLLATE
LC_TIME=$LC_COLLATE
export LC_COLLATE LC_NUMERIC LC_TIME
if test -n "$LC_ALL"
then
	test -n "$LANG" \
		|| die '$LC_ALL is set but $LANG is not.' \
			'This is not supported.'
	LANG=$LC_ALL
	unset LC_ALL
fi

UUID="726zjsd9l1l8af02fqy73s7am"

TFB=${TMPDIR:-/tmp}/${APP}_${UUID}_$$
REDIR250=
run mkdir -m 700 "$TFB"
trap cleanup 0

MAINDB=${TFB}/fsos
LINKDB=${TFB}/hardlinks
TMP1=${TFB}/temp1
TMP2=${TFB}/temp2
TMP3=${TFB}/temp3
TMP4=${TFB}/temp4
# Pass 1: Locate all file system objects.
inform "Gathering metadata for file system objects."
redir250 "$TMP1"
STATFMT='%D:%i %h maj=%t,min=%T,user=%u,group=%g'
STATFMT=$STATFMT',mode=%f,alloc=%bx%B,bytes=%s,mtime=%Y'
find "$SOURCE_TREE" | while read -r FSO
do
	system stat -c "$STATFMT" "$FSO"
	ID=${REPLY%% *}; REPLY=${REPLY#* }
	NLINKS=${REPLY%% *}; REPLY=${REPLY#* }
	# Include $NLINKS in metadata also.
	METADATA=$REPLY,links=$NLINKS
	RELPATH=${FSO#$SOURCE_TREE}; RELPATH=/${RELPATH#/}
	if test -L "$FSO"
	then
		system hashlink "$FSO"
		METADATA=$METADATA,symlinkhash=$REPLY
	elif test -d "$FSO"
	then
		NLINKS=1 # Do not record directory hardlinks.
	elif test -f "$FSO"
	then
		system hashfile "$FSO"
		METADATA=$METADATA,filedatahash=$REPLY
	fi
	if test $NLINKS -gt 1
	then
		echo "$ID $RELPATH" >& 250
	fi
	echo "$ID $NLINKS $METADATA $RELPATH"
done > "$TMP2"
cleanup250
# Create hardlink membership group hashes.
inform "Identifying hardlink path groups."
run sort -t' ' -k1 "$TMP1" > "$TMP3"
LAST_ID=
test -n "$SAVE_HARDLINKS" && redir250 "$TMP4"
{
	while IFS=" " read -r ID RELPATH
	do
		if test x"$ID" != x"$LAST_ID"
		then
			flush_linkid
			LAST_ID=$ID
		fi
		run printf '%s\n' "$RELPATH" >> "$TMP1"
	done
	flush_linkid
} < "$TMP3" > "$LINKDB"
if test -n "$SAVE_HARDLINKS"
then
	cleanup250
	run sort -t" " -k1 "$TMP4" > "$SAVE_HARDLINKS"
fi
# Incorporate hardlink hashes into main db.
inform "Add hardlink group references to file system object metadata."
test -n "$SAVE_METADATA" && redir250 "$TMP1"
while IFS=" " read -r ID NLINKS METADATA RELPATH
do
	if test $NLINKS -gt 1
	then
		system look -t" " "$ID" "$LINKDB"
		run test -n "$REPLY" # Exactly one match must be found.
		HASH=${REPLY##* }
		METADATA=$METADATA,hardlinkpathshash=$HASH
	fi
	system hashargs "$METADATA"
	echo "$REPLY $RELPATH"
	if test -n "$SAVE_METADATA"
	then
		echo "$REPLY $METADATA" >& 250
	fi
done < "$TMP2" | run sort -t" " -k2 > "$MAINDB"
if test -n "$SAVE_METADATA"
then
	cleanup250
	run sort -t" " -k1,1 "$TMP1" > "$SAVE_METADATA"
fi
# Finally, generate the result.
inform "Create checkpoint file."
{
	run echo "$UUID (File Format Identifier)"
	run echo "Original Source Tree Path: $SOURCE_TREE"
	system hashfile "$MAINDB"
	run echo "$REPLY (Hash of all the lines following this one)"
	run cat "$MAINDB"
} > "$CHECKPOINT_FILE"
inform "File \"$CHECKPOINT_FILE\" has been created."
